{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 440 Final Project: Neuro-Evolution of Augmenting Topology\n",
    "*An investigation into the processes and workings of the Neuro-Evolution of Augmenting Topology (NEAT) algorithm in Python.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Authors: Tom Shaw (shawtm@rams.colostate.edu) and Jennifer Dorcey (jdorcey@rams.colostate.edu)* \n",
    "\n",
    "*Fall 2017*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Artificial Intelligence algorithm that we investigated for this project was the effectiveness of the genetic algorithm NEAT on simple games such as the game Towers of Hanoi and the game Twenty Forty Eight. NEAT, which stands for Neuro-Evolution of Augmenting Topologies, is a genetic algorithm that is used in evolving artificial neural networks.  The main idea behind NEAT and why it is such a unique genetic algorithm is that it starts out evolving small, simple neural networks and continues to evolve these networks over many generations into highly sophisticated and complex networks.  NEAT aims to show how the evolution of neural networks over generations can be used to optimize and complexify solutions.  \n",
    "\n",
    "A neural networks functionality can be affected by its topology, its been shown that improved neural network efficiency resulted from topologies being minimized throughout evolution.  NEAT uses a genetic encoding scheme which allows corresponding genes to be lined up when two genomes, which are linear representations of network connectivity, cross over during mating.  Each genome contains a list of connected node genes.  These node genes provide the genome with a significant amount of information such as the in-node, out-node, weight of the connection, if the a gene has been expressed, and an innovation number for finding corresponding genes [[Stanley and Miikkulainen, 2002]](http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf).\n",
    "\n",
    "NEAT uses mutation along with reproducing to change a networks topology and connection weights.  It works by adding genes to a genome and there by gradually expanding the size of the genome.  When a connection mutation occurs, a new gene with a random weight is used to connect two unconnected nodes. Another mutation that can occur happens when an existing connection between two nodes is split up by adding a new node that is placed between the previously connected nodes.  Using this method of mutation, new nodes are able to be integrated into the network immediately, thus the network has more time to optimize itself.  As a result of mutation, genomes can be of varying sizes containing different connections residing in the same positions.  Explicit fitness sharing is another method of reproduction that is used by NEAT.  Fitness is used to measure the performance of a genome.  Genomes with a higher fitness have a greater chance of being selected to reproduce and there offspring will replace lower performing genomes [[Risi and Togelius, 2015]](https://arxiv.org/pdf/1410.7326.pdf).  This is how NEAT creates a new generation.\n",
    "\n",
    "We were able to implement our take on the NEAT algorithm to have most of the functionality that is described above.  There are a few main differences in how we chose to implement this algorthim, one of them being that we did not implement the concept of species, which allows a network to be further optimized by preserving a genome among a population. For example a genome that is particularly effective should be preserved and slightly mutated each time, allowing for the core of what made that genome successful to carry on in later generations. For simplicity of development our algorithm only maintains the champion's genome and uses that to breed with the other more successful genomes.  While this is not totally effective at maintaining a genome, it allows for some form of approximation as to what species would do in the algorithm.  We later found out that this approach was unsuitable for the scope of this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first steps we took in beginning this project involved deciding how we could generalize \"game\" classes so that we could optimize our code and not be limited to only using one game to train and test our NEAT algorithm.  In order for our algorithm to successfully use a \"game\", we decided that every \"game\" class must define all of the following variables and functions:\n",
    "\n",
    "- `__init__(self):`  The constructor for the game class must contain these variables:\n",
    "    - `self.state:`  This will change throughout the program as it represents the current state of the game from start to finish.  \n",
    "    - `self.moves:`  Keeps track of how many moves have been made throughout the game.\n",
    "    - `self.goalState:`  The game state that is needed to win the game.\n",
    "\n",
    "- `__repr__(self):`  This function is used to print the current game state in a human readable format by using the command print(game).\n",
    "\n",
    "- `validMoves(self):`  There has to be a new move chosen at every state of a game.  The validMoves() function analyzes the current state of the game and then returns a list containing all of the legal moves that could be made given this current state.\n",
    "\n",
    "- `makeMove(self, move):`  This is how the game is able to change and update its current state.  The function is given a chosen legal move, which it then applies to the games current state, and updates the current state of the game to reflect this move.\n",
    "\n",
    "- `gameOver(self):`  The gameOver() function is used to check if current state of the game is the end of the game.  The function returns True if the games current state has reached its goal state or if there are no more legal moves that can be made given the current state.  It then resets the games state so that it is ready to be played again.  The function returns False if the game has not reached its goal state or if there are more moves that can be made given the current state of the game.\n",
    "\n",
    "- `newStateRep(self):`  This function represents the game state as a single list of elements that can be understood by a neural network effectively.\n",
    "\n",
    "- `inputSize(self):`  We use this function to get the number of inputs that will be used to create new neural networks.\n",
    "\n",
    "- `reset(self):`  After the game has completed or reached a state where there are no more legal moves to be made, the game resets itself so that it can be played again immediatly.\n",
    "\n",
    "- `fitness(self):`  The fitness function is used to determine the value of performance for the network that will be used when training and breeding neural networks. This is the function that is used to determine which genome is the champion and which other networks can be used to reproduce with the champion.\n",
    "\n",
    "Thus, as long as each \"game\" class has these specified variables and functions defined, our NEAT algorithm should be able to run by using the \"game\".\n",
    "\n",
    "We defined two game classes for this project which we used to train and test neural networks with our implementation of the NEAT algorithm.  The two game classes we have implemented are the Towers of Hanoi game and the Twenty Forty Eight game that was popular on mobile phones.  \n",
    "\n",
    "In the implementation of the TOH.py game class and Qnet.py, we reused some of our code from previous assignments and some of the code from [Lecture 21](http://nbviewer.jupyter.org/url/www.cs.colostate.edu/~anderson/cs440/notebooks/21%20Reinforcement%20Learning%20with%20a%20Neural%20Network%20as%20the%20Q%20Function.ipynb).  \n",
    "\n",
    "For the TwentyFourtyEight.py game class, we found a public [repository](https://github.com/jbutewicz/An-Introduction-to-Interactive-Programming-in-Python/blob/master/Principles%20of%20Computing%20Week%201/2048.py) on Github that we used as a reference to help us implement and define how our functions work within the class.\n",
    "\n",
    "We also used the code in [nn2.tar](http://www.cs.colostate.edu/~anderson/cs440/notebooks/nn2.tar) which includes neuralnetworks.py, scaledconjugategradient.py, and mlutils.py. However, in neuralnetworks.py, we removed all of the code for the class NeuralNetworksClassifier as we felt it did not apply directly to our project.\n",
    "\n",
    "Next, we mapped out how we wanted to implement the Neuron and Neat Neural Network classes so that we would be able to use these classes in our NEAT algorithm (the code for which is below).  The implementation for our NEAT algorithm is in Neat.py.  Within this class we have defined functions that train neural networks and test the current champion of the networks.  Our implementation of NEAT includes functions that are used to breed and mutate neural networks.\n",
    "\n",
    "We have also defined the class NeatNN.py such that a neural network is able to calculate the value for each neuron and pass along this value to every layer of neurons until the value can be calculated for the last layer of neurons.  NeatNN.py is also able to add new neurons to a neural network.  To be able to add these neurons, the network must first get all of the information about the gene that the neuron will be added to.  It then computes the elements for the new neuron and adds the neuron, along with the newly calculated weights, to the neural network.  Thus, the network is able to add a gene to any neuron-neuron combination. Each neural network can also determine if a mutation in the network should occur and what that mutation should be. Another important function that each neural network calculates is the value of its fitness.  Fitness is used to analyze how a network is performing.\n",
    "\n",
    "We use the class Neuron.py to add neurons to neural networks. It was necessary to write a Neuron class as the genes connecting neurons were not guarenteed, so a neuron that was capable of changing connections was required. Each neuron contains a list of all the weights that it is responsible for.  Neurons are capable of passing their value to various neurons in the network and can also add weights between themselves and other neurons in the network.  Another functionality that Neuron.py possesses is the ability to add the capacity and associated values for a neuron, it can also keep track of what index it resides in within the neural network it belongs to. \n",
    "        \n",
    "We worked closely together on many aspects of this project and both team mebers contributed significantly.  We created a GitHub repository for this project to make working as a team easier and more colobrative.  To begin, we decided together how we wanted to implement each aspect of our project.  Then we decied which aspects we would work on individually in order to better divide and conquer this project.  \n",
    "\n",
    "Jennifer was responsible for the implementation of the Towers of Hanoi game class, the Twenty Forty Eight game class, and getting Qnet.py to run with a general game parameter instead of only with the Towers of Hanoi game. She also wrote the Introduction and Methods Section in the projects Jupyter Notebook.  Tom was responsible for the implemetation of the Neat.py class, the NeatNN.py class, and the Neuron.py class.  We worked together to write the Results and Conclusion Sections in the projects Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load Neat.py\n",
    "\"\"\"\n",
    "Created on Sat Dec  2 13:33:44 2017\n",
    "\n",
    "@author: Tom Shaw and Jenn Dorcey\n",
    "\"\"\"\n",
    "import copy\n",
    "import time\n",
    "from NeatNN import NeatNeuralNetwork\n",
    "\n",
    "class Neat:\n",
    "    def __init__(self, problem):\n",
    "        global Name\n",
    "        Name = 0\n",
    "        self.problem = problem\n",
    "        self.networks = []\n",
    "        self.results = []\n",
    "        pass\n",
    "\n",
    "    # this method is the hub for training a neural network from scratch\n",
    "    def train(self):\n",
    "        # generate a new population of networks\n",
    "        self.generateInitalPopulation()\n",
    "        # train until a champion hits optimal fitness\n",
    "        while self.chooseChampion().fitness() != self.problem.getOptimal():\n",
    "            # print out the results of the last iteration\n",
    "            #print (\"here\")\n",
    "            startTime = time.time()\n",
    "            self.runNetworks()\n",
    "            endTime = time.time()\n",
    "            self.breedNetworks()\n",
    "            print(\"{}   {}\".format(self.networks[0].fitness(), endTime - startTime))\n",
    "            self.results.append([self.networks[0].fitness(), endTime - startTime])\n",
    "        return results\n",
    "\n",
    "    # This method is for testing the current champion\n",
    "    def test(self):\n",
    "        startTime = time.time()\n",
    "        champion = self.chooseChampion()\n",
    "        moves = champion.runNetwork(copy.deepcopy(self.problem))\n",
    "        endTime = time.time()\n",
    "        return [moves, champion.fitness(), endTime - startTime]\n",
    "\n",
    "    # This method runs all the currently generated networks\n",
    "    # TODO make this concurrent\n",
    "    def runNetworks(self):\n",
    "        for net in self.networks:\n",
    "            net.runNetwork(copy.deepcopy(self.problem))\n",
    "        return\n",
    "\n",
    "    # this method is resposible for breeding all the current networks\n",
    "    def breedNetworks(self):\n",
    "        newNetworks = []\n",
    "        self.prunePopulation()\n",
    "        # breed all standing networks with the champion\n",
    "        # may produce more than 100 networks but will be in the neighborhood\n",
    "        while len(self.networks) < 100:\n",
    "            for i in range(1, len(self.networks)):\n",
    "                self.breedTwo(0, i)\n",
    "        # mutate all current networks 3 times\n",
    "        self.mutateNetworks(10)\n",
    "        return\n",
    "\n",
    "    # this method removes the lower half of the networks\n",
    "    # this method also removes any network with a fitness of 0\n",
    "    def prunePopulation(self):\n",
    "        # remove all networks with a 0 fitness\n",
    "        for net in self.networks:\n",
    "            if net.fitness() == 0:\n",
    "                self.networks.remove(net)\n",
    "        self.sortNetworks()\n",
    "        while (len(self.networks) > 50):\n",
    "            self.networks.remove(self.networks[50])\n",
    "        return\n",
    "\n",
    "    # this method sorts networks based on their fitness\n",
    "    # highest fitnesses have the lower indexes\n",
    "    def sortNetworks(self):\n",
    "        tupleNets = [(net.fitness(), net) for net in self.networks]\n",
    "        tupleNets.sort(key=lambda x: x[0], reverse=True) \n",
    "        # REVIEW might need to be net[1] for net in tupleNets\n",
    "        self.networks = [net for fit, net in tupleNets]\n",
    "        pass\n",
    "\n",
    "    # this method is for breeding two individual networks\\\n",
    "    # has a .6 chance for keeping a neuron if that neuron isnt already kept\n",
    "    # attempts to keep all weights associated with that neuron\n",
    "    def breedTwo(self, indexOne, indexTwo):\n",
    "        newNetwork = NeatNeuralNetwork(copy.deepcopy(self.problem))\n",
    "        # get neurons\n",
    "        newNeurons = []\n",
    "        newNeurons = self.getNeurons(self.networks[indexOne], newNeurons)\n",
    "        newNeurons = newNeurons + self.getNeurons(self.networks[indexTwo], newNeurons)\n",
    "        # add neurons to network\n",
    "        for neuron in newNeurons:\n",
    "            newNetwork.addNeuronN(neuron)\n",
    "        # Make sure connections are valid\n",
    "        newNetwork.checkConnections()\n",
    "        self.networks.append(newNetwork)\n",
    "        return\n",
    "\n",
    "    # helper method that adds neurons to a list with a .6 chance\n",
    "    # ignores the first and last layers as they are special cases\n",
    "    def getNeurons(self, net, new):\n",
    "        for i in range(1, len(net.network) - 1):\n",
    "            for j in range(len(net.network[i])):\n",
    "                if self.neruonInList(net.network[i][j], new):\n",
    "                    if r.uniform(0, 1) < .8:\n",
    "                        new.append(net.network[i][j])\n",
    "        return new\n",
    "\n",
    "    # a helper function that checks if a neuron is in a list\n",
    "    # checks based off of neurons name\n",
    "    def neruonInList(self, neuron, listOfNeurons):\n",
    "        for neurons in listOfNeurons:\n",
    "            if neuron.name == neurons.name:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # this method is for signaling networks to mutate\n",
    "    # ignores the champion\n",
    "    def mutateNetworks(self, iterations):\n",
    "        self.sortNetworks()\n",
    "        for j in range(1, len(self.networks)):\n",
    "            for i in range(iterations):\n",
    "                self.networks[j].mutate()\n",
    "        return\n",
    "\n",
    "    # generates an inital set of networks\n",
    "    # these networks are starting from scratch\n",
    "    # so they need to be highly mutated at the start\n",
    "    def generateInitalPopulation(self):\n",
    "        for i in range(100):\n",
    "            newNetwork = NeatNeuralNetwork(copy.deepcopy(self.problem))\n",
    "            self.networks.append(newNetwork)\n",
    "        self.mutateNetworks(100)\n",
    "        return\n",
    "\n",
    "    # This method selects the highest fitness\n",
    "    # network from the current generation\n",
    "    def chooseChampion(self):\n",
    "        self.sortNetworks()\n",
    "        return self.networks[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load NeatNN.py\n",
    "\"\"\"\n",
    "Created on Sat Dec  2 15:27:23 2017\n",
    "\n",
    "@author: Tom Shaw\n",
    "\"\"\"\n",
    "from Neuron import Neuron\n",
    "import random as r\n",
    "\n",
    "global Name\n",
    "Name = 6\n",
    "class NeatNeuralNetwork:\n",
    "\n",
    "    def __init__(self, problem):\n",
    "        self.problem = problem\n",
    "        layer0 = []\n",
    "        for i in range(problem.inputSize()):\n",
    "            newneuron = Neuron(i, 0, i)\n",
    "            layer0.append(newneuron)\n",
    "        newneuron = Neuron(problem.inputSize(), 1, 0)\n",
    "        x = [newneuron]\n",
    "        self.network = [ layer0, x ]\n",
    "        #self.network[1].append(newneuron)\n",
    "       # print(\"NETWORK\")\n",
    "        #print(self.network)\n",
    "        #print (\"\\n \\n \\n\")\n",
    "        #print (self.network[0])\n",
    "        #print (\"\\n \\n \\n\")\n",
    "        #print (self.network[0][0])\n",
    "        self.neuronNames = [x for x in range(problem.inputSize() +1)]\n",
    "\n",
    "    def runNetwork(self, problem):\n",
    "        self.problem = problem\n",
    "        count = 0\n",
    "        while not self.problem.gameOver() and count < 100:\n",
    "            self.makeMove(self.chooseMove())\n",
    "            count += 1\n",
    "        return count\n",
    "\n",
    "    def chooseMove(self):\n",
    "        highestMoveScore = -10000\n",
    "        for moves in self.problem.validMoves():\n",
    "            temp = self.calculate(self.problem.newStateRep() + moves)\n",
    "            if temp > highestMoveScore:\n",
    "                highestMoveScore = temp\n",
    "                highestMove = moves\n",
    "        return highestMove\n",
    "\n",
    "    def checkZeros(self, values):\n",
    "        for i in values:\n",
    "            if i != 0:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def makeMove(self, move):\n",
    "        self.problem.makeMove(move)\n",
    "        return\n",
    "\n",
    "    # calculates the value of each neuron and passes it to the next layer\n",
    "    # returns the value of the last layer of neurons\n",
    "    def calculate(self, stateMove):\n",
    "        self.zeroLayer(stateMove)\n",
    "        for i in range(1, len(self.network)):\n",
    "            for j in range(len(self.network[i])):\n",
    "                self.network[i][j].compute()\n",
    "                self.network[i][j].share()\n",
    "        values = self.network[-1][0].getValue()\n",
    "        return values\n",
    "\n",
    "    # should go through and input the intial values\n",
    "    # into the first layer of the NN\n",
    "    def zeroLayer(self, stateMove):\n",
    "        for i in range(len(stateMove)):\n",
    "            self.network[0][i].value = stateMove[i]\n",
    "        return\n",
    "\n",
    "    # changes a weight to include a neuron in the middle\n",
    "    # neuron-neuron -> neuron-neuron-neuro\n",
    "    # with a random weight to the third neuron\n",
    "    def addNeuron(self):\n",
    "        # get the name for the new neuron\n",
    "        global Name\n",
    "        weights = self.getWeights()\n",
    "        # get information about the gene that we are adding a neuron to\n",
    "        toNeuron, index, fromNeuron = r.choice(weights)\n",
    "        x1, y1 = toNeuron.getNNetIndex()\n",
    "        x2, y2 = fromNeuron.getNNetIndex()\n",
    "        # compute elements of new neuron\n",
    "        x3 = ((x1 + x2) // 2)\n",
    "        if x3 == x1:\n",
    "            y3 = 0\n",
    "        else:\n",
    "            y3 = len(self.network[x3])\n",
    "        new = Neuron(Name, x3, y3)\n",
    "        self.neuronNames.append(Name)\n",
    "        Name += 1\n",
    "        # add in neuron to the right place\n",
    "        if x3 == x1:\n",
    "            self.network.insert(x1 + 1, [new])\n",
    "        elif x3 == x2:\n",
    "            self.network.insert(x2 - 1, [new])\n",
    "        else:\n",
    "            self.network[x3].append(new)\n",
    "        # add in new weights\n",
    "        new.makeAFriendi(toNeuron, index)\n",
    "        fromNeuron.makeAFriend(new)\n",
    "        fromNeuron.removeNeuron(toNeuron)\n",
    "        return\n",
    "\n",
    "    # a method that adds a neuron that is already created to the network\n",
    "    def addNeuronN(self, neuron):\n",
    "        names.append(neuron.name)\n",
    "        x = neuron.nnlayer\n",
    "        # check if network is long enough for x\n",
    "        while len(self.network) < x + 1:\n",
    "            self.network.insert(-2, [])\n",
    "        # add neuron to the layer it expects to be in\n",
    "        self.network[-2].append(neuron)\n",
    "        return\n",
    "\n",
    "    # checks that all connections are valid inside the network\n",
    "    def checkConnections(self):\n",
    "        for i in range(len(self.network) - 1):\n",
    "            for j in range(len(self.network[i])):\n",
    "                self.checkWeights(self.network[i][j])\n",
    "        return\n",
    "\n",
    "    def checkWeights(self, neuron):\n",
    "        for x in range(len(neuron.out)):\n",
    "            if neuron.out[x].name not in self.neuronNames:\n",
    "                neuron.removeNeuron(x[0])\n",
    "            else:\n",
    "                neuron.out[x] = self.findNeuron(neuron.out[x].name)\n",
    "        return\n",
    "\n",
    "    def findNeuron(self, name):\n",
    "        for i in range(len(self.network)):\n",
    "            for j in range(len(self.network[i])):\n",
    "                if name == self.network[i][j]:\n",
    "                    return self.network[i][j]\n",
    "                \n",
    "    # adds a gene to a random neuron-neuron combination\n",
    "    def addWeight(self):\n",
    "        # get the from neuron\n",
    "        fromNeurons = []\n",
    "        for i in range(len(self.network) - 1):\n",
    "            for j in range(len(self.network[i])):\n",
    "                fromNeurons.append(self.network[i][j])\n",
    "        fromNeuron = r.choice(fromNeurons)\n",
    "        # get to neuron\n",
    "        toNeurons = []\n",
    "        for i in range(fromNeuron.nnlayer, len(self.network)):\n",
    "            for j in range(len(self.network[i])):\n",
    "                toNeurons.append(self.network[i][j])\n",
    "        # generate weight\n",
    "        \n",
    "        toNeuron = r.choice(toNeurons)\n",
    "        fromNeuron.makeAFriend(toNeuron)\n",
    "        return\n",
    "\n",
    "    # method that changes the value of 2-3 weights\n",
    "    def changeWeights(self):\n",
    "        rand = r.randint(2, 3)\n",
    "        for i in range(rand):\n",
    "            self.changeWeight\n",
    "        return\n",
    "\n",
    "    # determines of a mutation should occur and if so,\n",
    "    # which mutation should happen\n",
    "    def mutate(self):\n",
    "        #print(self.network)\n",
    "        #print(\"\")\n",
    "        rand = r.uniform(0, 10)\n",
    "        if (rand < 2) and (len(self.getWeights()) != 0):\n",
    "            self.addNeuron()\n",
    "        elif rand < 5:\n",
    "            self.addWeight()\n",
    "        self.changeWeights()\n",
    "        return\n",
    "\n",
    "    # changes the weight of a random gene\n",
    "    # determines a high or low read and changes the weight to be either:\n",
    "    # low: change weight to midpoint of -1-weight\n",
    "    # high: change weight to be midpoint of weight-1\n",
    "    def changeWeight(self):\n",
    "        weights = self.getWeights()\n",
    "        toNeuron, index, fromNeuron = r.choice(weights)\n",
    "        rand = r.randint(0, 10)\n",
    "        if rand < 5:\n",
    "            toggle = False\n",
    "            toNeuron.cWeight(index, toggle)\n",
    "        else:\n",
    "            toggle = True\n",
    "            toNeuron.cWeight(index, toggle)\n",
    "        return\n",
    "\n",
    "    # gets a neuron, index combo for every out\n",
    "    # going node skipping the last layer\n",
    "    def getWeights(self):\n",
    "        ret = []\n",
    "        for i in range(len(self.network) - 1):\n",
    "            #print(\"NW i\")\n",
    "            #print(self.network[i])\n",
    "            for j in range(len(self.network[i])):\n",
    "                for w in self.network[i][j].getWeights():\n",
    "                    ret.append(w)\n",
    "        return ret\n",
    "\n",
    "    # returns the value of the fitness as described by the problem\n",
    "    def fitness(self):\n",
    "        return self.problem.fitness()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load Neuron.py\n",
    "\"\"\"\n",
    "Created on Sat Dec  2 14:47:11 2017\n",
    "\n",
    "@author: Tom Shaw\n",
    "\"\"\"\n",
    "import random as r\n",
    "\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, thisname, x, y):\n",
    "        self.inNeurons = []\n",
    "        # input weights\n",
    "        self.w = []\n",
    "        # input values\n",
    "        self.v = []\n",
    "        self.value = 0\n",
    "        # output neurons\n",
    "        self.out = []\n",
    "        self.outIndex = []\n",
    "        self.name = thisname\n",
    "        self.nnlayer = x\n",
    "        self.nnlindex = y\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"name: {}, number of weights: {}\".format(self.name, len(self.out))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"name: {}, number of weights: {}\".format(self.name, len(self.out))\n",
    "\n",
    "\n",
    "    # add a weight between this neuron and another neuron\n",
    "    def makeAFriend(self, other):\n",
    "        self.out.append(other)\n",
    "        self.outIndex.append(other.addWeight())\n",
    "        return\n",
    "\n",
    "    # add a weight with this neuron and another\n",
    "    # used when a neuron takes the place of another\n",
    "    def makeAFriendi(self, other, index):\n",
    "        self.out.append(other)\n",
    "        self.outIndex.append(index)\n",
    "        return\n",
    "\n",
    "    # adds capacity for a neuron and its associated value\n",
    "    # adds a random weight as an initial value\n",
    "    # returns the index to where fromNeuron should store value\n",
    "    def addWeight(self):\n",
    "        newIndex = len(self.w)\n",
    "        self.w.append(r.uniform(-1, 1))\n",
    "        self.v.append(0)\n",
    "        return newIndex\n",
    "\n",
    "    # sums the input values and their weights\n",
    "    def compute(self):\n",
    "        sum = 0\n",
    "        for i in range(len(self.w)):\n",
    "            sum += (self.w[i] * self.v[i])\n",
    "        self.value = sum\n",
    "        return\n",
    "\n",
    "    # method that controls sharing to all output neurons\n",
    "    def share(self):\n",
    "        for i in range(len(self.out)):\n",
    "            self.out[i].v[self.outIndex[i]] = self.value\n",
    "        return\n",
    "\n",
    "    # a getter for the current value\n",
    "    def getValue(self):\n",
    "        return self.value\n",
    "\n",
    "    # returns a list of all the weights this neuron is responsible for\n",
    "    def getWeights(self):\n",
    "        return [(self.out[i], self.outIndex[i], self)\n",
    "                for i in range(len(self.out))]\n",
    "\n",
    "    # a method that changes a random weight\n",
    "    def cWeight(self, index, toggle):\n",
    "        self.weight = w[index]\n",
    "        if toggle:\n",
    "            weight = ((weight + 1) / 2)\n",
    "        else:\n",
    "            weight = ((weight - 1) / 2)\n",
    "        self.w[index] = weight\n",
    "        return\n",
    "\n",
    "    # returns thsi neuron's indexing for the neural network its in\n",
    "    def getNNetIndex(self):\n",
    "        return (self.nnlayer, self.nnlindex)\n",
    "\n",
    "    # given another neuron, finds and removes the neruon from the outlist\n",
    "    def removeNeuron(self, other):\n",
    "        for i in range(len(self.out)):\n",
    "            #print(\"length : {}  ,  index:  {}\".format(len(self.out), i))\n",
    "            if self.out[i].name == other.name:\n",
    "                del self.out[i]\n",
    "                del self.outIndex[i]\n",
    "                break\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the course of development we made the choice to ignore the species aspect of the NEAT algorithm. As can be seen by our example below, the alorithm fails to maintain a champion properly which, after due consideration is not the result of any failing in the current code, but rather a flaw in the design which we attribute to the lack of species. In the algorithm species is used to maintain a certain genome that is resposible for higher fitness, and we attempted a very crude approximation of this using the champion system. We believe this to be the point of failure. As implemetation of a proper species system would both require knowledge and mastery of genertic algorithms, we believe that it is beyond our capacity and even more so beyond the scope of our project to implement such a system properly.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This the class that we were using to test our code.  Please make sure that this notebook is run from the same directory as the .tar file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitness: Time to run a generation\n",
      "16   4.8550732135772705\n",
      "16   5.4278810024261475\n",
      "16   5.031785011291504\n",
      "16   4.930129289627075\n",
      "32   4.717750072479248\n",
      "16   4.487974166870117\n",
      "32   4.5918567180633545\n",
      "16   4.866841793060303\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-3b1dbd2d39cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-3b1dbd2d39cb>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fitness: Time to run a generation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;31m#Start training TOH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m#print(\"TOWERS OF HANOI:\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Neat.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m#print (\"here\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mstartTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunNetworks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mendTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreedNetworks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Neat.py\u001b[0m in \u001b[0;36mrunNetworks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrunNetworks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetworks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NeatNN.py\u001b[0m in \u001b[0;36mrunNetwork\u001b[0;34m(self, problem)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgameOver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakeMove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchooseMove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TwentyFortyEight.py\u001b[0m in \u001b[0;36mgameOver\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoalState\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidMoves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoalState\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TwentyFortyEight.py\u001b[0m in \u001b[0;36mvalidMoves\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmoves\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                     \u001b[0mmoves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmoves\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %load Driver.py\n",
    "import Qnet\n",
    "from TOH import TOH\n",
    "from TwentyFortyEight import TwentyFortyEight\n",
    "import os\n",
    "import psutil\n",
    "import time\n",
    "from Neat import Neat\n",
    "\n",
    "def main():\n",
    "        \n",
    "    #the memory usage before the start of the current Python process\n",
    "    #process = psutil.Process(os.getpid())\n",
    "    #startMem = process.memory_info().rss/10**9, 'GB'\n",
    "\n",
    "    hiddenLayers = [40]\n",
    "    nReplays = 0\n",
    "    nIterations = 20\n",
    "    epsilon = 0.8\n",
    "    epsilonDecayFactor = 0.99\n",
    "    nReplays = 0\n",
    "    toh = TOH()\n",
    "    tfe = TwentyFortyEight()\n",
    "    \n",
    "    net = Neat(tfe)\n",
    "    print(\"fitness: Time to run a generation\")\n",
    "    net.train()\n",
    "    #Start training TOH\n",
    "    #print(\"TOWERS OF HANOI:\")\n",
    "    #startTohTrain = time.time()\n",
    "    #qnet, outcomes, samples = Qnet.trainQnet(50, hiddenLayers, nIterations, nReplays, \n",
    "    #                                epsilon, epsilonDecayFactor, toh)\n",
    "    #endTohTrain = time.time() - startTohTrain\n",
    "    #print(\"TOTAL TIME TO TRAIN TOWERS OF HANOI: \", endTohTrain)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Start training TOH\n",
    "    #print(\"TOWERS OF HANOI:\")\n",
    "    #startTohTrain = time.time()\n",
    "    #qnet, outcomes, samples = Qnet.trainQnet(100, hiddenLayers, nIterations, nReplays, epsilon, epsilonDecayFactor, toh)\n",
    "    #endTohTrain = time.time() - startTohTrain\n",
    "    #print(\"TOTAL TIME TO TRAIN TOWERS OF HANOI: \", endTohTrain)\n",
    "\n",
    "    #Start testing TOH\n",
    "    #startTohTest = time.time()    \n",
    "    #endTohTest = time.time() - startTohTest\n",
    "\n",
    "    #Start training TwentyFortyEight\n",
    "    #print()\n",
    "    #print(\"TWENTY FORTY EIGHT:\")\n",
    "    #startTfeTrain = time.time()\n",
    "    #qnet, outcomes, samples = Qnet.trainQnet(50, hiddenLayers, nIterations, nReplays, \n",
    "    #                                epsilon, epsilonDecayFactor, tfe)\n",
    "    #endTfeTrain = time.time() - startTfeTrain\n",
    "    #print(\"TOTAL TIME TO TRAIN TWENTY FORTY EIGHT: \", endTfeTrain)\n",
    "    #print()\n",
    "    #print(\"TWENTY FORTY EIGHT:\")\n",
    "    #startTfeTrain = time.time()\n",
    "    #qnet, outcomes, samples = Qnet.trainQnet(100, hiddenLayers, nIterations, nReplays, epsilon, epsilonDecayFactor, tfe)\n",
    "    #endTfeTrain = time.time() - startTfeTrain\n",
    "    #print(\"TOTAL TIME TO TRAIN TWENTY FORTY EIGHT: \", endTfeTrain)\n",
    "    \n",
    "    #Start testing TFE\n",
    "    #startTfeTest = time.time()\n",
    "    #endTfeTest = time.time() - startTfeTest\n",
    "   \n",
    "    #the memory usage after the process completes\n",
    "    #endMem = process.memory_info().rss/10**9, 'GB'\n",
    "    #totalMem = endMem[0] - startMem[0] \n",
    "    #print()\n",
    "    #print(\"TOTAL MEMORY USED BY PROGRAM IN GB: \", totalMem) \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even in \"failure\" we both learned a tremendous about about Artificial Intelligence and the NEAT algorithm while working on this project. Along our path we encountered many problems that exlain the workings of Artificial Intelligence as a whole, not just relating to the NEAT algorithm.  For example, why we use a fully connected network instead of one that evolves its connections. In Tandem the problems we encountered in developing this project helped to grow and mature our coding abilites and knowledge of Artificial Intelligence.\n",
    "\n",
    "Although this project took a lot of work from both of us and we appear to have failed, we have succeeded in a few ares.  First, we were successful in generalizing a neural network package to work with a specific problem taken in as an object, and were able to implement two such problems, manifest as Towers of Hanoi and Twenty Fourty Eight games. All in all, this entire process of researching, learning a new algorithm, and honing in on a plan and idea has taught us how to work better in a team and just how in-depth these genetic algorithms are.  This is a fascinating area of Computer Science and we both hope to learn as much as we can about it.\n",
    "\n",
    "We both aggreed that this project can be shown to the general the public.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [[Anderson, 2017]](http://nbviewer.jupyter.org/url/www.cs.colostate.edu/~anderson/cs440/notebooks/21%20Reinforcement%20Learning%20with%20a%20Neural%20Network%20as%20the%20Q%20Function.ipynb) Reinforcement Learning: Replacing the Q table with a Neural Network\n",
    "\n",
    "- [[Anderson, 2017]](http://www.cs.colostate.edu/~anderson/cs440/notebooks/nn2.tar) nn2.tar\n",
    "\n",
    "- [[2048 GitHub Repository, 2014]](https://github.com/jbutewicz/An-Introduction-to-Interactive-Programming-in-Python/blob/master/Principles%20of%20Computing%20Week%201/2048.py)\n",
    "\n",
    "- [[Stanley, 2014]](https://www.cs.ucf.edu/~kstanley/neat.html) The NeuroEvolution of Augmenting Topologies (NEAT) Users Page\n",
    "\n",
    "- [[Risi and Togelius, 2015]](https://arxiv.org/pdf/1410.7326.pdf) Neuroevolution in Games:\n",
    "State of the Art and Open Challenges\n",
    "\n",
    "- [[Stanley and Miikkulainen, 2002]](http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf) Evolving Neural Networks through\n",
    "Augmenting Topologies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
